---
layout: post
title:      "The AI Models that Could Increase Diversity Inclusion in Media"
date:       2020-07-10 09:27:52 +0000
permalink:  the_ai_models_that_could_increase_diversity_inclusion_in_media
---


I am a person of color. In myself this is not something I feel that defines me, it is not something that I identify myself as. If I were a hermit, never interacting with other people for years I have the intuition that this definition would evaporate from my perspective. My skin color would not fade, but its relative meaning would, there would be no one for me to be lighter or darker than.
However I am not isolated from the world, no matter how much I put energy to isolating my worldview from the binding pressures of the collective conscious we often refer to as society and culture. Our society has historically and presently been vitiated by a bias around not only ethnicity, but gender, sexuality, age, and nearly any other symbol one can use to represent themselves, and therefore others. While it is debatable whether bias is an inherent human quality, and perhaps even deeper a basic parameter of observation, at present the racial biases that we refer to as racism has expressed itself for so long, like a while loop with no stop condition that runs ad infinitum until it inexorably crashes our shared system. Many of us today find ourselves, and our efforts attempting to make a break statement that stops this flow and heals the damage it has caused.
There are many ways one can perceive and define bias. As a someone who practices data science, I am familiar with the ways that an abundance of bias can render algorithms that are meant to understand the world skewed and unfunctional. Often when my machine learning models are suffering from bias it is due to the data they are fed. All too often I find myself comparing people to these ML algorithms, that have been fed information about the world, and labels about themselves that are misshapen and not aligned with reality. I wanted to address this phenomenon particularly in the dimension of media as it is where so many of us receive the lion’s share of data about the world, and use machine learning to empower those that desire to, the means to take action against this bias.
Enter Generative Adversarial Networks
With the creative force of Generative Adversarial Networks (GANs), we are able to generate lifelike faces that are able to be animated and mapped on the current faces within movies, television shows, online learning platforms, advertisements, and any other media that showcases human faces when combined with First Order Motion Models.
Image for post
DCGAN Architecture
For the purposes of the hypothetical business case related to Netflix, I used GANs to create images resembling the faces of a person’s social media network, which can be used to supplant the original cast in a movie or television show being streamed on the Netflix platform.

Concept for using custom casts in media
If the users of a media platform could make conscious choices on the images they observed, how might this impact that individual’s perceptions of the world around them overtime? Even more curiously I ask, how could this choice impact how they see themselves? At the time of this work, there have been countless occurrences of violence and hatred towards PoC and those individuals that have been classified as minorities across the globe, and especially within my home country of the United States. As someone that has been labeled as a minority, and has dealt with the under representation and misrepresentation of those that look like me, I personally feel that the G/A system offers a ray of hope that it is possible to change the way that humans as a whole interact with each other, and view each other. That all of those working to heal the wounds of the present and the past will succeed and that the end result will be a world of acceptance, appreciation, and peace not only with others, but within one’s self.
As a Data Scientist’s work should not end with asking themselves questions and forming opinions, I devised a survey to obtain data on others’ views on the matter, and found hopeful results. While the sample size was relatively small, the group was more diverse than I initially thought.
Image for post
Demographics of Survey Sample
When asked: “In your opinion, could this format of viewing media create more diversity in the videos people see in general? ”, there is an overwhelming amount of positive responses.
“In your opinion, could this format of viewing media create more diversity in the videos people see in general? ”
Image for post
When taking a deeper look into the demographics of those that felt that this system could increase diversity inclusion in media, it was striking to see that across all ethnicities, and age groups, there was a majority that felt it was capable of such a task.
Image for post
Answers to: “In your opinion, could this format of viewing media create more diversity in the videos people see in general?”
Further when prompted with the question: “How do you think this system could change general perceptions of stereotypes?”, respondents offered rich opinions, some hopeful about the effects the G/A system could have, while others were more skeptical and even felt it could make matters worse, creating echo chambers that would amplify the effects of a preexisting bias.
“How do you think this system could change general perceptions of stereotypes?”
Image for post
Results from running Sentiment Analysis on responses
When conducting further analysis of the responses to this question, I used the Natural Language Tool Kit sentiment analysis model to understand the general views that people had in regard to the G/A system changing stereotypes in general, and found a higher ratio of positive views.
Image for post
WordCloud of responses to “How do you think this system could change general perceptions of stereotypes?”
Here we see that some of the most common words in our response are “people”, ‘to “see”, “diversity”, “AI”, “media”, and “think”. Looking at these words alone yields the notion that the general opinion is that AI can help people think and see diversity in media, which is the sole purpose of this work.
For the hypothetical focus on Netflix adopting this technology to their platform, respondents were asked: Which would you prefer for watching movies and TV?
Which would you prefer for watching movies and TV?
Image for post
Here we see that a majority of film and television viewers would prefer to have the choice of intertwining the original cast with a cast of their own making, be it comprised of generated faces, themselves, or friends and family. This trend continued into other areas of media as well.
Image for post
Overall these findings can be considered in favor of the G/A system bringing more diversity to the user base of Netflix, and to media in general. This system along with other actions could lead to an improvement in the representation of minorities in media, which could lead to countless changes in the current landscape of social relations around the world. Furthermore, the G/A system presents us with an opportunity to view ourselves in a new light, one potentially freed from the limitations that our current culture have placed on many of us.
If you would like to help this project come to life, please share. If you are interested in collaboration, you can contact me at my LinkedIn:
https://www.linkedin.com/in/morgan-jones-datascience/
If you would like to view the code for this project, feel free to view it at the following GitHub repository:
https://github.com/MoJoMoon/Deep-Learning-for-Diversity-Inclusion-in-Media
I wish you well and peace during these times. Thank you.
